# Planejamento da Avaliação do Protótipo de Papel

## Introdução

A fim de garantir o bom andamento e a qualidade do projeto serão utilizados os prótotipos de papel pois com eles é possível avaliar as ideias iniciais das ações para realizar as tarefas sem que necessite de grande esforço técnico principalmente no design para ter um protótipo. Nessa seção iremos planejar todos os passos dessa avaliação de modo que tenhamos uma documentação fidedigna com os conceitos trabalhados em classe.

---

## Metodologia

A metodologia segue o framework **DECIDE**, onde cada etapa é detalhada a seguir:

### Tabela 1 - Framework DECIDE

| Letra |                          Definição                           |
| :---: | :----------------------------------------------------------: |
|   D   |            Determinar os objetivos da avaliação.             |
|   E   |   Explorar perguntas a serem respondidas com a avaliação.    |
|   C   |     Escolher os métodos de avaliação a serem utilizados.     |
|   I   | Identificar e administrar as questões práticas da avaliação. |
|   D   |          Decidir como lidar com as questões éticas.          |
|   E   |         Avaliar, interpretar e apresentar os dados.          |

Fonte: [Ana Joyce](https://github.com/anajoyceamorim).

---

## Determinar os objetivos da avaliação

Para essa avaliação temos como objetivo identificar erros ou possíveis modificações nos protótipos de baixa fidelidade a fim de determinar melhorias e promover a conformidade com os artefatos produzidos anteriormente.
Os objetivos serão os seguintes:

1. Comparar ideias e alternativas de design
2. Identificar problemas na interação e interface

---

## Explorar perguntas a serem respondidas com a avaliação

Com base nos objetivos levantadados anteriormente visa explorar as questões abaixo:

### Tabela 2 - Perguntas da avaliação

|           Objetivo a ser respondido            |                                                              Pergunta                                                               |
| :--------------------------------------------: | :---------------------------------------------------------------------------------------------------------------------------------: |
|    Comparar ideias e alternativas de design    |                                  Qual das alternativas é a mais eficiente? Mais fácil de aprender?                                  |
|    Comparar ideias e alternativas de design    |                                              Qual delas os usuários preferem? Por quê?                                              |
| Identificar problemas na interação e interface | O usuário consegue operar o sistema? / Ele atinge seu objetivo? Com quanta eficiência? Em quanto tempo? Após cometer quantos erros? |
| Identificar problemas na interação e interface |                                                O usuário consegue operar o sistema?                                                 |
| Identificar problemas na interação e interface |                                     Que parte da interface e da interação o deixa insatisfeito?                                     |

Fonte: BARBOSA, S. D. J.; SILVA, B. S. Interação Humano-Computador. Rio de Janeiro: Elsevier, 2011.

---

## Escolher os métodos de avaliação a serem utilizados

Assim como Barbosa e Silva (2011) citam ao falar sobre o método de observação podemos dizer que permite ao avaliador
coletar dados sobre situações em que os participantes realizam suas atividades, com
ou sem apoio de tecnologia computacional. O registro e a análise desses dados permitem identificar problemas reais que os participantes enfrentaram, e não apenas
problemas potenciais previstos pelo avaliador como em uma avaliação por inspeção.
Há o método adaptado de observação para prototipação em papel e esse será utilizado para o grupo.

Outro ponto relatado no Livro de IHC (Barbosa e Silva, 2021) é que terminada a sessão de interação, os avaliadores devem conduzir a entrevista pós-teste. Essa entrevista é uma oportunidade para coletar a opinião do participante sobre a experiência de uso que acabou de vivenciar e esclarecer eventuais dúvidas sobre seu comportamento e suas intenções, percepções e interpretações durante a execução das tarefas.

---

## Identificar e administrar as questões práticas da avaliação

### Recrutamento

Para o recrutamento de pessoas para execução do método de avaliação por prototipação em papel iremos avaliar pessoas que estão alinhadas com o [perfil de usuário](https://interacao-humano-computador.github.io/2024.2-Cinemark/Analise-de-requisitos/perfil-de-usuario/) elencados assim como é orientado (Barbosa e Silva, 2021). Ele também fala que se possível não utilize amigos, familiares ou conhecidos visto que esses podem deixar de relatar problemas na avaliação ao achar que estarão criticando o trabalho realizado. Dessa forma, caso seja necessário fazer alguma entrevista com eles que se oriente de isso o objetivo da avaliação e foco das observações.

Devemos destacar que de acordo com Nielsen (1990) é viável realizar uma avaliação somente com cinco pessoas tendo menos gastos de tempo e outros recursos e estatisticamente garantido o mesmo resultado de uma pesquisa com um grupo grande de pessoas

### Preparação

Para a avaliação do prótotipo de papel foram escolhidas as seguintes tarefas:

- **Cinemark Club**: Inscrição e consulta de benefícios.
- **Compra de ingressos e snacks**: Seleção de filmes, sessões, e compra de snacks.
- **Reserva de salas**: Agendamento e confirmação de reservas.
- **Voucher corporativo**: Gerenciamento e utilização de vouchers corporativos.

Tais tarefas serão desenvolvidas em protótipos de papel para que tais materiais sejam utilizados durante a avaliação.

### Custos

Temos como objetivo o custo mínimo em nossas avaliações e para tal iremos buscar utilizar materiais já adquiridos para a produção do protótipo e escolheremos um local silencioso, tranquilo e gratuito para realização da avaliação.

### Prazos

Planeja-se realizar as entrevistas em método observador de acordo com as seguintes datas:

#### Tabela 3 - Cronograma esperado

| Entrevistadores                                    | Entrevistado  | Data       | Duração | Tarefa                    | Local              |
| -------------------------------------------------- | ------------- | ---------- | ------- | ------------------------- | ------------------ |
| [Ana Joyce](https://github.com/anajoyceamorim)     | Maria Eduarda | 06/01/2025 | --      | --                        | Faculdade UnB Gama |
| [Anne de Capdeville](https://github.com/nanecapde) | Solange       | 06/01/2025 | --      | Reserva de Salas          | Faculdade UnB Gama |
| [José Oliveira](https://github.com/Jose1277)       | Sofia         | 07/01/2025 | --      | --                        | Faculdade UnB Gama |
| [Pedro Miguel](https://github.com/pedroMADBR)      | Bruno         | 08/01/2025 | --      | Cadastro do Cinemark Club | Faculdade UnB Gama |
| [Pedro Miguel](https://github.com/pedroMADBR)      | Pedro         | 08/01/2025 | --      | Cadastro do Cinemark Club | Faculdade UnB Gama |

Fonte: [Pedro Miguel](https://github.com/pedroMADBR).

### Roteiro de perguntas

As perguntas serão trabalhadas a partir da seção [Explorar perguntas](#explorar-perguntas-a-serem-respondidas-com-a-avaliação) que se baseiam nos [objetivos](#determinar-os-objetivos-da-avaliação) selecionados para essa avaliação.

---

## Decidir como lidar com as questões éticas

- Será obtido consentimento dos participantes antes da entrevista.
- Garantia de anonimato e confidencialidade das respostas coletadas.
<!-- ADICIONAR TERMO DE CONSENTIMENTO -->

---

## Avaliar, interpretar e apresentar os dados

Com os dados das entrevistas devidamente documentados e organizados nos materiais do grupo de trabalho será possível interpretá-los com base no contexto apresentado para o entrevistado e os fatores da entrevista, como artíficio de comparação utilizaremos a gravação também. Dessa forma poderemos avaliar as questões apresentadas e anotar as melhorias observadas, os novos caminhos levantados e correções para as próximas etapas.

---

## Teste Piloto

O objetivo do teste piloto serve como uma etapa preliminar para garantir que o teste de usabilidade principal seja bem-sucedido. Ele tem vários objetivos fundamentais:

- Verificação do Processo:
  O teste piloto permite validar todo o procedimento do teste, incluindo a configuração do ambiente, a clareza das instruções e a execução das tarefas. Isso assegura que tudo esteja funcionando como planejado.

- Detecção de Problemas Técnicos:
  Essa fase ajuda a identificar falhas técnicas, como erros no software ou problemas com equipamentos, que podem ser corrigidos antes do teste principal.

- Avaliação das Tarefas:
  O piloto verifica se as tarefas são adequadas e compreensíveis para os participantes. Se as tarefas forem muito complexas ou simples, ajustes podem ser feitos para melhorar a eficácia do teste.

- Ajuste de Ferramentas e Questionários:
  Questionários ou outras ferramentas de coleta de dados também são testados para garantir que as perguntas sejam claras e relevantes, possibilitando ajustes antes do teste definitivo.

- Preparação da Equipe:
  O teste piloto permite que a equipe responsável pelo teste se familiarize com o processo e resolva quaisquer dúvidas ou problemas, garantindo que estejam prontos para o teste principal.

- Economia de Tempo e Recursos:
  Ao identificar e resolver problemas durante o piloto, a equipe evita retrabalho e economiza tempo e recursos durante o teste completo.

- Coleta de Dados Iniciais:
  Essa etapa inicial também fornece uma amostra dos dados que serão coletados, permitindo ajustes na metodologia para garantir resultados mais precisos e úteis.

Em suma, o teste piloto é crucial para assegurar que o teste de usabilidade seja eficiente, identificando e corrigindo potenciais problemas antes da execução final.

## Resultado do Teste Piloto - Reserva de Salas

Abaixo segue o vídeo feito do teste piloto realizado por [Anne](https://github.com/nanecapde).

<p style="text-align: center"><a href="https://youtu.be/shp9NlqMNw" target="blanket">Clique aqui</a></p>

<font size="3"><p style="text-align: center">Fonte: [Anne](https://github.com/nanecapde).</p></font>

## Referências Bibliográficas

> BARBOSA, S. D. J.; SILVA, B. S. Interação Humano-Computador. Rio de Janeiro: Elsevier, 2011.

---

> Nielsen, J. e Molich, R. “Heuristic evaluation of user interfaces”. Proceedings of ACM CHI’90, pp. 249–256, 1990.

---

## Histórico de versões

| Versão |                    Descrição                     |                     Autor(es)                      |    Data    |                    Revisor(es)                     | Data de revisão |
| :----: | :----------------------------------------------: | :------------------------------------------------: | :--------: | :------------------------------------------------: | :-------------: |
|  1.0   |               Criação do documento               |   [Pedro Miguel](https://github.com/pedroMADBR)    | 06/01/2025 | [Anne de Capdeville](https://github.com/nanecapde) |   06/01/2025    |
|  1.1   |                    Correções                     | [Anne de Capdeville](https://github.com/nanecapde) | 14/01/2025 |   [Pedro Miguel](https://github.com/pedroMADBR)    |   14/01/2025    |
|  1.2   | Alteração dos objetivos e correção do cronograma |   [Pedro Miguel](https://github.com/pedroMADBR)    | 14/01/2025 | [Anne de Capdeville](https://github.com/nanecapde) |   14/01/2025    |
